{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930d3425-067f-4563-8161-ce3a6ce3152f",
   "metadata": {},
   "source": [
    "# Project - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9249ff-4707-4022-90f7-6d5a72b03b45",
   "metadata": {},
   "source": [
    "# PRCP-1000-PortugueseBank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d5756-3bf7-4b66-9007-d253cf7abfb1",
   "metadata": {},
   "source": [
    "### Problem Defination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2217f-8b46-4a53-99c9-220a3bdad2e0",
   "metadata": {},
   "source": [
    "The goal is to predict whether a customer will subscribe to a term deposit based on various personal and socio-economic features. The dataset is derived from marketing campaigns conducted by a Portuguese bank, where the outcome variable (y) represents whether a customer subscribes to a term deposit or not. The challenge involves working with an imbalanced dataset, where the majority of customers did not subscribe to the deposit (No), while a minority did (Yes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8777eb-9ba0-4a3f-a2cf-7f2bf5a03f68",
   "metadata": {},
   "source": [
    "## **Attribute Information** \n",
    "**The various featureof the dataset explained below**\n",
    "1. Age : (numeric)\n",
    "2. Job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3. Marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4. Education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5. Eefault: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6. Housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7. Loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "8. Contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9. Month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10. Day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11. Duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no')\n",
    "12. Dampaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. Pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. Previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. Poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "16. Emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17. Cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18. Cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19. Euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20. Nr.employed: number of employees - quarterly indicator (numeric)\n",
    "21. y - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b6707-adf1-4b68-b937-fc9e1a04203e",
   "metadata": {},
   "source": [
    "## Business Goal\n",
    "**The goal is to build and optimize classification models that can accurately predict whether a customer will subscribe to a term deposit (binary outcome: Yes or No) while handling the imbalance in the data to improve predictions for the minority class (Yes).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5f89e-d671-4bcb-aa04-df4c3ebe53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d147b7-55ff-4aff-ba95-a9893ee3356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Dataset\n",
    "data=pd.read_csv('PortugeseBank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a623a-66dd-411e-9dd4-953b5e2f6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2d504-d266-4439-8f59-0136c9a9f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This profiling report will provide complete info about the data\n",
    "from ydata_profiling import ProfileReport\n",
    "Profile = ProfileReport(data, title = 'Portugese Bank Report')\n",
    "Profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b257b326-c76d-422b-ab2d-5eb5ac976c49",
   "metadata": {},
   "source": [
    "## Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccd077-9eff-4453-b6d6-a2c042b3419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data ## Checking head and tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089f24a-6591-49cc-b57d-965b73f5ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326d8df-71e0-48ce-b022-0c6055d45233",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8614fff-b934-40d3-97b5-4e456b9272d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() ## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6195c7d-5051-474b-a3df-da81dd073e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002a0e9-6c20-436e-abc6-fe059b33979b",
   "metadata": {},
   "source": [
    "# EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37ff43-6a44-4978-ad8e-dc36c27a56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting numerical and categorical features\n",
    "data_cat=data[['Job', 'Martial', 'Education', 'Default', 'Housing', 'Loan', 'Contact',\n",
    "       'Month', 'Day_of_week', 'Poutcome', 'y']]\n",
    "data_num=data[['Age', 'Duration', 'Campaign', 'Pdays', 'Previous', 'Emp.var.rate',\n",
    "       'Cons.price.idx', 'Cons.conf.idx', 'Euribor3m', 'Nr.employed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afaa33-2571-4bc6-ab07-d6e164a0d19e",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026316d1-fcab-4cc3-a98c-ca5021b0ef60",
   "metadata": {},
   "source": [
    "**Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c50f4-bbb3-4100-98a1-d2f8c3ee5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "for column in data_num:\n",
    "    if plotnumber<=16:\n",
    "        ax = plt.subplot(5,2,plotnumber)\n",
    "        sns.distplot(x=data_num[column],kde=True, color='k')\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fabed-e459-4fe1-9d2e-b45b979da003",
   "metadata": {},
   "source": [
    "**Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0195430-4462-4c0c-9686-caf9550a3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking Count of Categotical features\n",
    "value_counts = {col: data_cat[col].value_counts() for col in data_cat.columns}\n",
    "for col, counts in value_counts.items():\n",
    "    print(f\"Value counts for {col}:\")\n",
    "    print(counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b99f1-16ae-4ca8-b62b-63724ac877c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "for column in data_cat:\n",
    "    if plotnumber<=16:\n",
    "        ax = plt.subplot(6,2,plotnumber)\n",
    "        sns.countplot(x=data_cat[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ed539-16c3-4e35-841c-5e2a53a4d1d5",
   "metadata": {},
   "source": [
    "## Insights from univariate analysis\n",
    "\n",
    "**Numerical Features**\n",
    "* Age : The age distribution is right-skewed, with most customers falling between 30-40 years old. A few older customers exist as outliers.\n",
    "* Duration : The duration of the last contact call shows that longer calls tend to lead to better outcomes, though the majority of calls are short (less than 200 seconds).\n",
    "* Campaign and Previous : Most customers have been contacted a limited number of times, and few customers have been contacted through multiple campaigns.\n",
    "\n",
    "**Categorical Features**\n",
    "* Job : Common jobs include \"blue-collar\", \"management\", and \"technician\", with \"student\" and \"retired\" customers having a higher likelihood of subscribing.\n",
    "* Marital Status : Most customers are married, with a smaller proportion being single or divorced. Single customers are more likely to subscribe than married ones.\n",
    "* Education : Most customers have secondary or tertiary education. Higher education correlates with a higher subscription rate.\n",
    "* Housing : A large portion of customers have housing loans\n",
    "* Default and Loan : People with no default and no loan more.\r\n",
    "* Contact: People who have been contacted via cellular network are mo..e\n",
    "* y(Target) : The classes no and yes are highly imbalanced with majority no values and very few positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4f849-7f17-42bb-a8a5-0c3e6f42a2fb",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458488e-8a67-4781-8c29-05512ebf1026",
   "metadata": {},
   "source": [
    "**Categorical Features VS Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e317e92-b258-4b43-bdf8-803de2ef9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "for column in data_cat:\n",
    "    if plotnumber<=16:\n",
    "        ax = plt.subplot(6,2,plotnumber)\n",
    "        sns.countplot(x=data_cat[column],hue=data_cat.y)\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be3aff-ca24-4ebb-a417-57d0b9cfb100",
   "metadata": {},
   "source": [
    "**Numerical Features VS Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d6d76-626a-4a9a-866e-eed0a6249d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "for column in data_num:\n",
    "    if plotnumber<=16:\n",
    "        ax = plt.subplot(5,2,plotnumber)\n",
    "        sns.histplot(x=data_num[column],hue=data_cat.y)\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4d31c-633d-49e1-88db-2a79ab1acf9a",
   "metadata": {},
   "source": [
    "## Insights from Bivariate Analysis\n",
    "* Age vs Subscription: Older customers and younger ones (20-30) tend to subscribe more frequently than middle-aged customers (30-40), who have lower subscription rates.\n",
    "* Job vs Subscription: Job types like \"admin\", \"blue-collar\", and \"technician\" have higher subscription rates, while other workers have lower subscription rates.\n",
    "* Duration vs Subscription: Longer call durations are positively correlated with higher subscription rates. Calls lasting over 300 seconds (5 minutes) are more likely to result in a subscription.\n",
    "* Campaign: The length of contact calls and previous campaign outcomes are strong predictors. Longer calls and successful prior campaigns boost the likelihood of a successful subscription.\n",
    "* Education vs Subscription: Customers with higher levels of education (tertiary) tend to subscribe more frequently than those with lower levels of education (primary).\n",
    "* Default and Loan vs Subscriptions : People without default and loans tend to subscribe more frequently.\n",
    "Previous Campaign Outcome vs Subscription: If the customer had a successful outcome in the previous campaign, they are much more likely to subscribe again.\n",
    "* Demographic Variables: Variables like age, job, and education are strong indicators of whether a customer will subscribe. Younger, highly educated customers with professional jobs are more likely to subscribe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a6eca-b386-47be-ab6c-d9889726a5c0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe176912-87df-48df-9ce4-95ac5a4a5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling Missing Values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d6ced-8c97-42f9-8edd-ad9aa402b5d4",
   "metadata": {},
   "source": [
    "**There is no missing values, so we will continue with next steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4735e-6702-42f7-8b2f-1c1beb4f6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114de66-0076-40f9-9d74-3a4203145505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping Duplicates\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42224b5f-9b60-4b75-ab98-dc54c146eb0a",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8db8da-f1c5-4f4c-bafa-48a656500ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating box plot to check the outliers\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber=1\n",
    "\n",
    "for column in data_num:\n",
    "    if plotnumber<=16:\n",
    "        ax=plt.subplot(6,2,plotnumber)\n",
    "        sns.boxplot(x=data_num[column], color='k')\n",
    "        plt.xlabel(column, fontsize=15)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89fb7d4-1511-4322-bcb9-53f48862288a",
   "metadata": {},
   "source": [
    "**Outliers Treatment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38c67f-4d40-4045-9bf0-7b5e6b198f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating def function for outlier treatment\n",
    "def Outliers_IQR(data,column):\n",
    "    IQR = st.iqr(data[column],interpolation='midpoint')\n",
    "    print(f'IQR: {IQR}')\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    print(f'The 25\\u1d57\\u02b0 percentile of {column} : {Q1}' )\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    print(f'The 75\\u1d57\\u02b0 percentile of {column} : {Q3}' )\n",
    "    Upper_limit = Q3 + 1.5*IQR\n",
    "    print(f'The Upper_limit of {column} : {Upper_limit}' )\n",
    "    Lower_limit = Q1 - 1.5*IQR\n",
    "    print(f'The Lower_limit of {column} : {Lower_limit}' )\n",
    "    Lower_Out_data = data.loc[data[column]<Lower_limit]\n",
    "    print(f'The Lower Outlier data of {column} : {len(Lower_Out_data)}')\n",
    "    Upper_Out_data = data.loc[data[column]>Upper_limit]\n",
    "    print(f'The Upper Outlier data of {column} : {len(Upper_Out_data)}')\n",
    "    Outlier_Per = (2406/len(data))*100\n",
    "    print(f'The Outlier percentage of {column} : {Outlier_Per}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f35ac6-cbd6-49a3-a21e-f3ae4d73fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating the extreme values of age feature\n",
    "Outliers_IQR(data,'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb4cd2-bf61-4f0a-9f6d-e9da992c6a8b",
   "metadata": {},
   "source": [
    "**It doesn't make any sense for students under 18 years to open a bank term deposit or even get a housing or a personal loan. So removing these values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef2903-2b90-4647-bf5a-efa808ee7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Age']<18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804616c0-f40f-4d06-908c-b9aea5360920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataset to include only individuals who are 18 years old or older.\n",
    "data=data[data['Age']>=18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509fa88-b9c7-486e-a493-48d8543f8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating the extreme values of age feature\n",
    "Outliers_IQR(data,'Campaign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f343b-18a2-4fbf-8034-33400e8043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Campaign']>10,'Campaign'].value_counts()[-6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59409b48-fbc6-41ba-9946-8255315c6459",
   "metadata": {},
   "source": [
    "**Observing the above data, lot of data lies after 75th percentile so it would make no sense to those values, it is significant from the box plot above as well.So we will just remove the extreme value 56.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2829f2-d5b2-4d86-a82b-fe80dca1b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the extreme value row in Campaign for filtering the dataset\n",
    "data=data[data['Campaign']<56]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c750ee4-5477-474f-8141-ab1fa10ebf4a",
   "metadata": {},
   "source": [
    "# Encoding - Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456c721-f6bc-45fa-9650-048daccb2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c70ef1-294b-4889-856e-b4a26c496251",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding for Job, Martial, Contact, Month, Day_of_week, Poutcome as they does not follow any hierarchy or rank\n",
    "data = pd.get_dummies(data=data,columns=['Job','Martial','Contact','Month','Day_of_week','Poutcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6949b42-0425-494d-a48d-249112dc8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label encoding for Education, Default, Housing, Loan\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data['Education'] = labelencoder.fit_transform(data['Education'])\n",
    "data['Default'] = labelencoder.fit_transform(data['Default'])\n",
    "data['Housing'] = labelencoder.fit_transform(data['Housing'])\n",
    "data['Loan'] = labelencoder.fit_transform(data['Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d428e-2f4f-4bfc-939b-2f8362850ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Encoding for dependent variable y\n",
    "data.replace({'yes':1, 'no':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5205e5f-1691-464c-aac4-1718b80da42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbb380-0bea-4f20-9a4a-07862147e752",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4446d5-b47d-4b64-8711-afd639f50a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking correlation\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data_num.corr(),annot=True,fmt='.1g',xticklabels=data_num.columns.values,yticklabels=data_num.columns.values,cmap=\"YlGnBu\",cbar=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cddc2a81-415a-4b36-8f16-506df71a7542",
   "metadata": {},
   "source": [
    "1. There is no relationship among the numerical data.\n",
    "2. There is no constant feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aea717-bbb6-4511-90e5-0add01f134bd",
   "metadata": {},
   "source": [
    "**As the duration feature highly affects the output target. Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known, so this input only used for benchmark purposes and will be dropped.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8605a-556c-4fd5-b404-9edb10ef5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping Duration column\n",
    "data.drop('Duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e2b5f-15eb-49b6-9376-12b3bb4f8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d59ecf3-b128-43a0-a815-6d25b70c0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final data\n",
    "Final_data=data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4339f-4797-4363-8b58-46e084727700",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad0829-035f-4665-bc2b-cab832c17fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning Independent and Dependent Variable\n",
    "X=data.drop('y', axis=1)\n",
    "y=data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ad232-c50d-4d15-80f7-78e3cc0fe6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bf96e-1bd5-4579-95a1-3b211888b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffccd80-4553-46bb-a6b1-ffa650936b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23281f6c-f16c-4e9b-831b-ed1eb911d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['Age','Campaign','Pdays','Emp.var.rate','Cons.price.idx','Cons.conf.idx','Euribor3m','Nr.employed']]=scaler.fit_transform(X_train[['Age','Campaign','Pdays','Emp.var.rate','Cons.price.idx','Cons.conf.idx','Euribor3m','Nr.employed']])\n",
    "X_test[['Age','Campaign','Pdays','Emp.var.rate','Cons.price.idx','Cons.conf.idx','Euribor3m','Nr.employed']]=scaler.transform(X_test[['Age','Campaign','Pdays','Emp.var.rate','Cons.price.idx','Cons.conf.idx','Euribor3m','Nr.employed']])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1535890a-77e5-44d3-acb3-4ad6531f1966",
   "metadata": {},
   "source": [
    "SMOTE was applied to balance the imbalanced target classes, where the 'No' responses significantly outnumber the 'Yes' responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4e749-88c6-45f9-9f8e-58da84571808",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Smote - Balancing data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE() ## object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07f19e-46b0-4053-96ef-73245625449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb46a52-ff23-4361-a08f-13ded15b1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Actual Classes\",Counter(y_train))\n",
    "print(\"SMOTE Classes\",Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b9d5b-6ee5-430a-8360-a2991c5269c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04833adc-a192-4145-9fe1-52785f9aba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27aa40a-3db7-48de-927f-856e7d207b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Class_Model): ## Defining a function\n",
    "    print(f'IMBALANCE DATA') \n",
    "    print(f'Model Name : {Class_Model}') ## Object Creation\n",
    "    model = Class_Model.fit(X_train, y_train) ## Training the data\n",
    "    print(f'Training score : {model.score(X_train,y_train)}') ## Training data score\n",
    "    y_predict = model.predict(X_test) ## Predicting test data\n",
    "    print(f' Predictions are : {y_predict}') ## Predicted data\n",
    "    print('\\n')\n",
    "    print(f'MODEL EVALUATION')\n",
    "    conf_matrix= confusion_matrix(y_test, y_predict)\n",
    "    print(f'confusion matrix')\n",
    "    print(conf_matrix)\n",
    "    print(f'Classification Report')\n",
    "    print(classification_report(y_test,y_predict))\n",
    "    print(f'f1_score: {f1_score(y_test,y_predict)}')\n",
    "    print('\\n')\n",
    "    print(f'SMOTE DATA')\n",
    "    print(f'Model Name : {Class_Model}')\n",
    "    model = Class_Model.fit(X_train_smote, y_train_smote)\n",
    "    print(f'Training score : {model.score(X_train_smote, y_train_smote)}')\n",
    "    y_predict_Smote = model.predict(X_test)\n",
    "    print(f' Predictions are : {y_predict_Smote}')\n",
    "    print('\\n')\n",
    "    print(f'MODEL EVALUATION')\n",
    "    conf_matrix= confusion_matrix(y_test, y_predict_Smote)\n",
    "    print(f'Confusion matrix')\n",
    "    print(conf_matrix)\n",
    "    print(f'Classification Report')\n",
    "    print(classification_report(y_test,y_predict_Smote))\n",
    "    print(f'f1_score: {f1_score(y_test,y_predict_Smote)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00c21b-66be-4a0d-8cc8-dcd7b0c2976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "predict(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7052f-93a0-468a-81aa-fbcd524a0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Support Vector Classifier\n",
    "predict(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5e9fc-142b-426f-820b-9f5a5f2b221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree Classifier\n",
    "predict(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d902e20-14c8-4ae0-b07f-0090539258ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Classifier\n",
    "predict(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175dd0b0-ebc6-4e7e-a5e3-e18c657344e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging Classifier\n",
    "predict(BaggingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84850b13-ca6e-4d47-8966-9b139d88ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "predict(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c4189-a39f-4a2b-b8e7-6d86e6139363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Models=[]\n",
    "Models.append(('LR',LogisticRegression()))\n",
    "Models.append(('SVM',SVC()))\n",
    "Models.append(('DT',DecisionTreeClassifier()))\n",
    "Models.append(('RF',RandomForestClassifier()))\n",
    "Models.append(('BC',BaggingClassifier()))\n",
    "Models.append(('GB',GradientBoostingClassifier()))\n",
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae448c-680a-43bc-8538-10b35f4e4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking Cross validation scores\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "my_cv = []\n",
    "my_names = []\n",
    "\n",
    "for name, model in Models:\n",
    "    cv = cross_val_score(model,X_train_smote,y_train_smote,cv=10,scoring='f1')\n",
    "    my_names.append(name)\n",
    "    my_cv.append(cv)\n",
    "    scores = ('%s %f (%f)' % (name, cv.mean(), cv.std()))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b91ca-3883-4bd4-a4b3-481233c91b20",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea7472-1fd6-4255-be11-c947e165fb73",
   "metadata": {},
   "source": [
    "After creating multiple classification models, both RandomForest and GradientBoosting performed well in their base models, so we will tune both the models with different Hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe0edd-2b74-4db5-87e7-7adcf9fef3fb",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning for RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac344f4-5d6b-4e6e-912f-eb77f9a9ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing randomizedsearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e776c0d-28f4-400a-bd97-36a9148d54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating dictionary for Parameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [100,120,150,180,200,240],\n",
    "    'max_depth': [5,10,15,20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf':[2,4,6,12,15,20],\n",
    "    'max_features':['sqrt','log2'],\n",
    "    'criterion': ['gini', 'entropy'],'bootstrap': [True, False]  \n",
    "}\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(rf, param_distributions, n_iter=100, scoring='f1', cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82a061-d27f-48e9-9bc1-9da1bc036bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(RandomForestClassifier(n_estimators=100, min_samples_split=5,min_samples_leaf=2,max_depth=20,max_features='sqrt',bootstrap=False,random_state=42,criterion='entropy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969b968-e6f9-4af8-816c-e7d996b22710",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning for GradientBoosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bd93a-b1a0-44f6-b3e6-1802c90c65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating dictionary for Parameters\n",
    "param_distributions = {\n",
    "    'n_estimators': [100,120,150,180,200,240],\n",
    "    'max_depth': [5,10,15,20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf':[2,4,6,12,15,20],\n",
    "    'max_features':['sqrt','log2'],\n",
    "    'loss':['log_loss','exponential'],\n",
    "    'learning_rate':[0.1,0.001,0.0001,0.02],\n",
    "    'criterion':['friedman_mse','squared_error']\n",
    "}\n",
    "# Initialize the model\n",
    "GB = GradientBoostingClassifier()\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(GB, param_distributions, n_iter=50, scoring='f1', cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b8109-d9cc-4dc3-b07d-1cbfe7734028",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(GradientBoostingClassifier(n_estimators=120, min_samples_split=10,min_samples_leaf=2,max_depth=20,learning_rate=0.1,max_features='log2',loss='log_loss',criterion='friedman_mse'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "489e43f5-c8d1-4b96-904a-0f68fd09cc05",
   "metadata": {},
   "source": [
    "1.In this tuning process, RandomForest and GradientBoosting classifiers were subjected to hyperparameter tuning in an effort to improve the model's performance, particularly for the minority class (class 1). Despite tuning, the recall scores for class 1 (indicating the model's ability to correctly identify positive instances) showed little to moderate improvement in both models.\n",
    "2. Given the minimal gains, we shifted to Recursive Feature Elimination (RFE) as an alternative approach for feature selection.\n",
    "In addition to tuning RandomForest and GradientBoosting, we will also apply RFE to the Logistic Regression model, which had shown promising results in its base form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ee8e0-3e49-4f5a-8642-b2c99f2704e6",
   "metadata": {},
   "source": [
    "## Applying Recursive Feature Elimination(RFE) with cross-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1d47c-9e3f-402e-8c77-3bbabe7668aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f31127-08ae-491b-9aa5-5bb5dff05014",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating def function for elimination_crossval\n",
    "def elimination_crossval(model):\n",
    "\n",
    "    rfe=RFE(estimator=RandomForestClassifier(),n_features_to_select=10)\n",
    "    \n",
    "    #Fitting the rfe\n",
    "    X_rfe=rfe.fit_transform(X_train_smote,y_train_smote)\n",
    "    \n",
    "    #Transforming X_test\n",
    "    X_rfe_test=rfe.transform(X_test)\n",
    "    \n",
    "    model=model\n",
    "    \n",
    "    #Creating pipeling to avoid data leakage\n",
    "    pipeline=Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    \n",
    "    cv=RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "\n",
    "    scores =cross_val_score(pipeline,X_rfe, y_train_smote, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print('Accuracy for model with cross val: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))\n",
    "    \n",
    "    \n",
    "    #Fitting the pipeline\n",
    "    fitted_model=pipeline.fit(X_rfe,y_train_smote)\n",
    "    \n",
    "    y_preds=fitted_model.predict(X_rfe_test)\n",
    "    \n",
    "    #Printing the classification report\n",
    "    print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e62bdb-a419-4478-9483-027be72a78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elimination_crossval(LogisticRegression(max_iter=7600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e367fa2-cf52-48f0-8c91-cd483ce82f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elimination_crossval(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abe3dd4f-f57b-4dc4-b826-cbdb371b6fe5",
   "metadata": {},
   "source": [
    "The tuning efforts for RandomForest and GradientBoosting provided marginal improvements in recall for class 1, but they still struggled to correctly predict the minority class. By switching to Logistic Regression combined with Recursive Feature Elimination (RFE), a much better recall was achieved for class 1, improving from 58% to 70% and accuracy of 75. This suggests that RFE with Logistic Regression can be a more effective approach when the primary objective is to improve recall for the minority class, especially in imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85219c69-bb96-42f2-bee6-632213ae6501",
   "metadata": {},
   "source": [
    "## **Data Analysis Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42052b8e-fc21-4ce1-91e6-47e058cb05fd",
   "metadata": {},
   "source": [
    "#### **1. Introduction**\n",
    " \n",
    "   The purpose of the analysis is to how the bank runs a marketing campaign to bring customers on board with the term deposits.\r\n",
    "\n",
    "\n",
    "#### **2. Data Overview**\n",
    "\n",
    " - Number of rows: 41188\n",
    " - Number of columns: 21\n",
    " -  Featues: Age, Duration, Campaign, Pdays, Previous, Emp.var.rate, Cons.price.idx, Cons.conf.idx, Euribor3m, Nr.employed, Job, Martial, Education, Default, Housing, Loan, Contact, Month, Day_of_week, Poutcome, y(Target.))\n",
    " - Target Variable : y(Bank Term Deposit Subrcription).\n",
    "#### **3. Data Preprocessing and Feature Engineering**\n",
    "   \n",
    "- **Handling Missing Values** : The dataset contains no missing values, ensuring data completeness and consistenc.\n",
    " - **Handling categorical data** : For the categorical features like Job, Marital, Education, Default, Housing, Loan, Contact, Month, Day_of_week, Poutcome, and y (Target) in the Portuguese bank data, a combination of one-hot encoding and label encoding was applied based on real-world hierarchies and domain understanding. One-hot encoding was used for features without inherent order, such as Job, Martial, Contact, Month, Day_of_week, Poutcome. Meanwhile, label encoding was applied to ordinal features like Education and Default, Housing and Loan, reflecting their natural ranking to improve model interpretability and performance. And for target variable(y) manual encoding was done. This balanced approach captures both nominal and ordinal relationships effectively\n",
    " - **Outliers** : Handling outliers was crucial for improving model accuracy, but in some cases, extreme values might represent valid customer behaviors, so after careful analysis. The data includes records of students under 18, which is unrealistic for opening a bank term deposit or obtaining loans like housing or personal loans. Therefore, removing these values is a logical step to ensure data relevance and accuracy. In the Campaign feature lot of data lies after 75th percentile so it would make no sense to those values, it is significant from the box plot above as well. So we removed the extreme value 56\n",
    "- **Feature Transformation**:  MinMax scaling was applied to the features Age, Campaign, Pdays, Emp.var.rate, Cons.price.idx, Cons.conf.idx, Euribor3m, and Nr.employed because the data was not normally distributed, making standard scaling less appropriate. By using MinMaxScaler, the features were scaled to a range of 0 to 1, preserving the original distribution of the data while normalizing the feature values. This ensures that no feature disproportionately influences the model due to diffrent scales.\n",
    "\n",
    "#### **4. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "- **Age vs Subscription**: Older customers and younger ones (20-30) tend to subscribe more frequently than middle-aged customers (30-40), who have lower subscription rates.\n",
    "- **Job vs Subscription**: Job types like \"admin\", \"blue-collar\", and \"technician\" have higher subscription rates, while other workers have lower subscription rates.\n",
    "- **Duration vs Subscription**: Longer call durations are positively correlated with higher subscription rates. Calls lasting over 300 seconds (5 minutes) are more likely to result in a subscription.\n",
    "- **Education vs Subscription**: Customers with higher levels of education (tertiary) tend to subscribe more frequently than those with lower levels of education (primary).\n",
    "- **Previous Campaign Outcome vs Subscription**: If the customer had a successful outcome in the previous campaign, they are much more likely to subscribe again.\n",
    "- **Default and loan vs Subscription**: People without loans tend to subscribe more frequently.\n",
    "- **Demographic Variables**: Variables like age, job, and education are strong indicators of whether a customer will subscribe. Younger, highly educated customers with professional jobs are more likely to subscribe.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8767e9-4782-4c77-844f-d0623ede66fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Overview of Models Evaluated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84349f12-aa59-46fd-b277-ffcadf372382",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy Score: 0.81\n",
    "- Precision: 0.30\n",
    "- Recall: 0.58\n",
    "- F1 Score: 0.39\n",
    "  \n",
    "#### Support Vector Classifier (SVC)\n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy Score: 0.83\n",
    "- Precision: 0.34\n",
    "- Recall: 0.59\n",
    "- F1 Score: 0.43\n",
    "\n",
    "#### Decision Tree Classifier\n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy Score: 0.84\n",
    "- Precision: 0.30\n",
    "- Recall: 0.37\n",
    "- F1 Score: 0.33\n",
    "\n",
    "#### Random Forest Classifier\n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy Score: 0.88\n",
    "- Precision: 0.46\n",
    "- Recall: 0.40\n",
    "- F1 Score: 0.42\n",
    "\n",
    "#### Bagging Classifier:\n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy Score: 0.88\n",
    "- Precision: 0.44\n",
    "- Recall: 0.34\n",
    "- F1 Score: 0.38\n",
    "\n",
    "\n",
    "#### Gradient Boosting Classifier: \n",
    "\n",
    "Performance Metrics:\n",
    "- Accuracy Score: 0.88\n",
    "- Precision: 0.44\n",
    "- Recall: 0.53\n",
    "- F1 Score: 0.48\n",
    "\n",
    "## Model Performance Comparison\n",
    "\n",
    "#### Best Model: \n",
    "\n",
    "After creating multiple classification models, Both RandomForest and GradientBoosting performed well in their base models, achieved overall scores as below.\n",
    "\n",
    "1.RandomForest Classifier:\n",
    "- Precision (Class 1): 0.46\n",
    "- Recall (Class 1): 0.40\n",
    "- Accuracy: 0.88\n",
    "- F1 Score: 0.42\n",
    " \n",
    "2.GradietBoosting Classifier:\n",
    "- Precision (Class 1): 0.53\n",
    "- Recall (Class 1): 0.44\n",
    "- Accuracy: 0.88\n",
    "- F1 Score: 0.48\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5fe66d-ca5d-4598-b728-088d1bba58ef",
   "metadata": {},
   "source": [
    "## **Model Tuning Summary**\n",
    "\n",
    "The primary goal of model tuning was to enhance the performance of the Random Forest (RF) and Gradient Boosting (GB) models, particularly focusing on improving recall for the minority class (customers likely to subscribe to term deposits).\n",
    "\n",
    "**Tuning Process**\n",
    "\n",
    "In this tuning process, RandomForest and GradientBoosting classifiers were subjected to hyperparameter tuning in an effort to improve the model's performance, particularly for the minority class (class 1). Despite tuning, the recall scores for class 1 (indicating the model's ability to correctly identify positive instances) showed little to moderate improvement in both models. For RandomForest, recall slightly increased from 40% to 43%, and for GradientBoosting, recall decreased from 53% to 37% as boosting focuses on best balance between precision, recall and overall performance\n",
    "\n",
    "To further improve the results, Recursive Feature Elimination (RFE) was applied to Logistic Regression, Gradient boosting where the goal was to enhance the recall for class 1. This method yielded a significant improvement, achieving a recall of 70% for class 1 in Logistic Regression although at the cost of some accuracy in the overall classification.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The tuning efforts for RandomForest and GradientBoosting provided marginal improvements in recall for class 1, but they still struggled to correctly predict the minority class. By switching to Logistic Regression combined with Recursive Feature Elimination (RFE), a much better recall was achieved for class 1, improving from 58% to 70% and accuracy of 75. This suggests that RFE with Logistic Regression can be a more effective approach when the primary objective is to improve recall for the minority class, especially in imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ea89a-81e4-4e20-8ecd-5d64a1fe8190",
   "metadata": {},
   "source": [
    "## **Suggestions to the Bank market team to make customers buy the product.**\n",
    "\n",
    "The most important features which the bank should focus on to attract more customers to buy term deposit are:\n",
    "- Duration\n",
    "- Age\n",
    "- Campaign\n",
    "- Euribo3\n",
    "- nr.employed\n",
    "\n",
    "\r\n",
    "1.Duration being one of the most influential factors,i.e. the higher the call duration the higher the chances of a sale. So the bank should focus on enhancing the quality of calls by building a rapport with the customers, decreasing wait time, checking in with the customers, and most importantly take feedback from the customers.\r\n",
    "\r\n",
    "2.Age feature demonstrates that the majority term deposit purchasing capacity lies within the age group of 25-58 yrs adults. So, the bank should target this age group more and allocate more resources in getting in the customers from this particular ag\n",
    "\n",
    "3.Campaign feature is important as it indicates the number of calls made during the current campaign. The customers do not like to get bothered with too many calls so a sweet spot lies within 1-5 calls, again depending upon the interest of the customer. So the bank should focus on training the sales team so that they can know the interested and non-interested customers based on the behavior,voice modulations, tone, and pitch of the customer.\r\n",
    "\r\n",
    "4.Euribo3 is indicative of the trend that the higher interest rates attract more customers. So there are two things which the bank can pursue which are as follows: -Target the age group which is liable to get higher interest rates (4.5-5) particularly. -Increase the marketing campaign when the interest rates are higher, which can help in bringing more clients on board with the term deposits.\r\n",
    "\r\n",
    "5.nr.employed trend indicates that more number of employees leads to more number of customers, which makes sense because if there are more employees, more leads can be targeted, proper followups and check-ins can be done. On the other hand, customer satisfaction could be achieved by creating a dedicated after-sales team. So, the bank should focus on hiring more people.e group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea49ed1-6261-4d45-8fd8-f5f2f3bb5e74",
   "metadata": {},
   "source": [
    "## **Report on Challenges faced**\n",
    "\n",
    "**1.Imbalanced Dataset**:\n",
    "\n",
    "- Challenges : The dataset exhibited significant class imbalance, with a predominant number of 'No' responses compared to 'Yes' for term deposits. This imbalance led to models that performed well on accuracy but failed to adequately predict the minority class.\n",
    "- Solution : Implementing oversampling techniques like SMOTE effectively balanced the classes, allowing for improved model training and better identification of the minority class.\n",
    "\n",
    "**2.Model Performance Variability**:\n",
    "\n",
    "- Challenges : Different models, including Logistic Regression, Random Forest, and Gradient Boosting, demonstrated varying performance metrics, particularly in terms of recall for the positive class. Initial iterations yielded low recall rates for potential customers.\n",
    "- Solution : Utilizing advanced metrics such as F1-score and precision-recall curves provided a clearer evaluation of model performance, ensuring a focus on improving recall for the positive class.\n",
    "\n",
    "**3.Hyperparameter Tuning**:\n",
    "\n",
    "- Challenges : Tuning hyperparameters for complex models like Random Forest and Gradient Boosting was time-consuming and resource-intensive. Despite various tuning attempts, improvements were minimal, leading to a need for an effective strategy to optimize model performance without excessive computational load.\n",
    "- Solution : By using more efficient search strategies like RandomizedSearchCV, along with systematic evaluation of a reduced set of hyperparameters, streamlined the tuning process and reduced computational load.\n",
    "\n",
    "**4.Feature Selection Complexity**:\n",
    "\n",
    "- Challenges : Identifying relevant features that contributed significantly to model performance was challenging. Implementing Recursive Feature Elimination (RFE) revealed that while some features were beneficial, others introduced noise, complicating the model training process.\n",
    "- Solution : Combining RFE with domain knowledge helped in selecting impactful features while reducing noise, leading to enhanced model performance.\n",
    "\n",
    "**5.Evaluation Metrics Confusion**:\n",
    "- Challenges : The reliance on accuracy as a metric was misleading due to the imbalanced nature of the dataset. This necessitated a shift in focus toward metrics like precision, recall, and F1-score to better assess model performance, particularly in correctly identifying the minority class.\n",
    "- Solution : Establishing a consistent evaluation framework centered on precision, recall, and F1-score ensured a comprehensive assessment of model effectiveness, particularly for the minority class.\n",
    "\n",
    "**6.Computational Resource Limitations**:\n",
    "- Challenges : Some models, particularly ensemble methods like Gradient Boosting, required substantial computational resources, resulting in longer training times and kernel crashes. This created bottlenecks in the model development process.\n",
    "- Solution : To address computational resource limitations, I relied solely on local resources without utilizing cloud computing or distributed systems. This approach led to longer training times, requiring patience while the kernel executed the model training processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863db54-d4be-4cad-a1cf-47bf238b8c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
